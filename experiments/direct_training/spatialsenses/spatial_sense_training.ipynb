{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6391c450",
   "metadata": {},
   "source": [
    "# Basic Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8613360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastai.distributed import *\n",
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../baselines'))\n",
    "if module_path not in sys.path: sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfea57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "core_pth = Path('/home/agrawalp2/prepositions'); assert core_pth.exists()\n",
    "spatialsenses_pth = core_pth/Path('real_world_data/spatialsense'); assert spatialsenses_pth.exists()\n",
    "encoder_path = core_pth/Path('experiments/baselines/models/encoder/GoogleNews-vectors-negative300.bin.gz'); assert encoder_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe3c56e",
   "metadata": {},
   "source": [
    "# Language only Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e10d774",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2efd6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.spatialsense.languageOnlyDataset import languageOnlyDataset\n",
    "from dataloaders.spatialsense.utils import  map_spatialsenses_to_stupd\n",
    "from models.static.language_only import SimpleLanguageOnlyModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca39ee",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab529db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 1319)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = languageOnlyDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                               split = 'train',\n",
    "                               encoder_path = encoder_path,\n",
    "                               x_tfms = None, \n",
    "                               y_tfms = [map_spatialsenses_to_stupd],)\n",
    "\n",
    "valid_ds = languageOnlyDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                               split = 'valid',\n",
    "                               encoder_path = encoder_path,\n",
    "                               x_tfms = None,\n",
    "                               y_tfms = [map_spatialsenses_to_stupd])\n",
    "\n",
    "len(train_ds),len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "176392fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size =64 , shuffle = True, drop_last = True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = 128 , shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc1de3",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e51d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "dls.n_inp = 2\n",
    "model = SimpleLanguageOnlyModel(word_embedding_dim=300, feature_dim=512, c=train_ds.c).cuda()\n",
    "learn = Learner(dls, model = model, loss_func = CrossEntropyLossFlat(), metrics = [accuracy,BalancedAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce23113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.607804</td>\n",
       "      <td>1.551673</td>\n",
       "      <td>0.407813</td>\n",
       "      <td>0.317455</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.403382</td>\n",
       "      <td>1.562047</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>0.333861</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.280012</td>\n",
       "      <td>1.645923</td>\n",
       "      <td>0.428906</td>\n",
       "      <td>0.359693</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.180857</td>\n",
       "      <td>1.705735</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.339253</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.097332</td>\n",
       "      <td>1.816023</td>\n",
       "      <td>0.420312</td>\n",
       "      <td>0.342171</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7eafb",
   "metadata": {},
   "source": [
    "# 2D Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1382e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.spatialsense.coordinate2dOnlyDataset import coordinate2D_OnlyDataset\n",
    "from dataloaders.spatialsense.utils import  map_spatialsenses_to_stupd\n",
    "from models.static.coordinate_2d_only import coordinateOnlyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75f1597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 1319)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = coordinate2D_OnlyDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                                    split = 'train',\n",
    "                                    x_tfms = None, \n",
    "                                    y_tfms = [map_spatialsenses_to_stupd])\n",
    "\n",
    "valid_ds = coordinate2D_OnlyDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                                    split = 'valid',\n",
    "                                    x_tfms = None, \n",
    "                                    y_tfms = [map_spatialsenses_to_stupd])\n",
    "\n",
    "len(train_ds),len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a399795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size =16, shuffle = True, drop_last = True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = 256, shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db13a0",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70678495",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "model = coordinateOnlyModel(10, 64, train_ds.c).cuda()\n",
    "learn = Learner(dls, model = model, loss_func = CrossEntropyLossFlat(), metrics = [accuracy,BalancedAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bab8f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.556026</td>\n",
       "      <td>1.502632</td>\n",
       "      <td>0.453906</td>\n",
       "      <td>0.344798</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.555371</td>\n",
       "      <td>1.497625</td>\n",
       "      <td>0.461719</td>\n",
       "      <td>0.358842</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.538176</td>\n",
       "      <td>1.451486</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.373809</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.517611</td>\n",
       "      <td>1.467898</td>\n",
       "      <td>0.478906</td>\n",
       "      <td>0.353542</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.516191</td>\n",
       "      <td>1.436629</td>\n",
       "      <td>0.492969</td>\n",
       "      <td>0.375480</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b129e0",
   "metadata": {},
   "source": [
    "# DRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9174d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.spatialsense.drnetDataset import drnetDataset\n",
    "from dataloaders.spatialsense.utils import  map_spatialsenses_to_stupd\n",
    "\n",
    "from models.static.drnet import DRNet\n",
    "\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53570aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 1319)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = drnetDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                        image_path = spatialsenses_pth/'images',\n",
    "                        encoder_path = encoder_path,\n",
    "                        split = 'train',\n",
    "                        y_category_tfms = [map_spatialsenses_to_stupd],\n",
    "                        x_img_tfms =     [transforms.ToPILImage(\"RGB\"),\n",
    "                                        transforms.RandomResizedCrop(224, scale=(0.75, 0.85)),\n",
    "                                        transforms.ColorJitter(0.1, 0.1, 0.1, 0.05)],\n",
    "                        bbox_mask_tfms = [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.Pad(4, padding_mode=\"edge\"),\n",
    "                                            transforms.RandomResizedCrop(32, scale=(0.75, 0.85))]\n",
    "                         )\n",
    "\n",
    "valid_ds = drnetDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                        image_path = spatialsenses_pth/'images',\n",
    "                        encoder_path = encoder_path, \n",
    "                        split = 'valid',\n",
    "                        y_category_tfms = [map_spatialsenses_to_stupd],\n",
    "                        x_img_tfms =     [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.CenterCrop(224)],\n",
    "                        \n",
    "                        bbox_mask_tfms = [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.Pad(4, padding_mode=\"edge\"),\n",
    "                                            transforms.CenterCrop(32)]\n",
    "                         )\n",
    "\n",
    "len(train_ds),len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c4ac972",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size =64 , shuffle = True, num_workers = 0)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = 128 , shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b688119",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "dls.n_inp = 4\n",
    "\n",
    "model = DRNet(word_embedding_dim = 300, \n",
    "              feature_dim = 512, \n",
    "              num_classes = train_ds.c, \n",
    "              num_layers = 3,\n",
    "              imagenet_pretrained = False).cuda()\n",
    "\n",
    "learn = Learner(dls, model = model, loss_func = CrossEntropyLossFlat(), metrics = [accuracy,BalancedAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e84011a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.590085</td>\n",
       "      <td>1.561749</td>\n",
       "      <td>0.408643</td>\n",
       "      <td>0.295358</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.453299</td>\n",
       "      <td>1.419746</td>\n",
       "      <td>0.488249</td>\n",
       "      <td>0.380180</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.370737</td>\n",
       "      <td>1.418625</td>\n",
       "      <td>0.460197</td>\n",
       "      <td>0.372836</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.310594</td>\n",
       "      <td>1.393764</td>\n",
       "      <td>0.491281</td>\n",
       "      <td>0.420533</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.250170</td>\n",
       "      <td>1.404946</td>\n",
       "      <td>0.503412</td>\n",
       "      <td>0.405813</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab707a",
   "metadata": {},
   "source": [
    "# ViPCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "875f0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.spatialsense.vipcnnDataset import vipcnnDataset\n",
    "from dataloaders.spatialsense.utils import  map_spatialsenses_to_stupd\n",
    "from models.static.vipcnn import VipCNN\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea6eac92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 1319)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = vipcnnDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                         image_path = spatialsenses_pth/'images',\n",
    "                         split='train',\n",
    "                         x_tfms = [transforms.ToPILImage(\"RGB\"),\n",
    "                                   transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
    "                                  ],\n",
    "                         y_category_tfms = [map_spatialsenses_to_stupd],\n",
    "                        )\n",
    "\n",
    "valid_ds = vipcnnDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                         image_path = spatialsenses_pth/'images',\n",
    "                         split='valid',\n",
    "                         x_tfms = [transforms.ToPILImage(\"RGB\")],\n",
    "                         y_category_tfms = [map_spatialsenses_to_stupd])\n",
    "\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ab0348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size =64 , shuffle = True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = 128 , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ade8fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.13 s, sys: 3.7 ms, total: 8.14 s\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%time x = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10ddb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "dls.n_inp = 3\n",
    "\n",
    "model = VipCNN(roi_size = 6, num_classes = train_ds.c, imagenet_pretrained = False).cuda()\n",
    "\n",
    "learn = Learner(dls, model = model, loss_func = CrossEntropyLossFlat(), metrics = [accuracy,BalancedAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d530143b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.758997</td>\n",
       "      <td>1.774824</td>\n",
       "      <td>0.345716</td>\n",
       "      <td>0.207544</td>\n",
       "      <td>02:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.657693</td>\n",
       "      <td>1.688529</td>\n",
       "      <td>0.373768</td>\n",
       "      <td>0.241650</td>\n",
       "      <td>02:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.605509</td>\n",
       "      <td>1.626857</td>\n",
       "      <td>0.393480</td>\n",
       "      <td>0.284832</td>\n",
       "      <td>02:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.554458</td>\n",
       "      <td>1.596805</td>\n",
       "      <td>0.415466</td>\n",
       "      <td>0.298099</td>\n",
       "      <td>02:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.509943</td>\n",
       "      <td>1.603270</td>\n",
       "      <td>0.411676</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>02:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dcb3f0",
   "metadata": {},
   "source": [
    "# PPRFCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8600c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.spatialsense.pprfcnDataset import pprfcnDataset\n",
    "from dataloaders.spatialsense.utils import  map_spatialsenses_to_stupd\n",
    "from models.static.pprfcn import PPRFCN\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "251e2323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 1319)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = pprfcnDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                         image_path = spatialsenses_pth/'images',\n",
    "                         split='train',\n",
    "                         x_tfms = [transforms.ToPILImage(\"RGB\"),\n",
    "                                   transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
    "                                  ],\n",
    "                         y_category_tfms = [map_spatialsenses_to_stupd],\n",
    "                        )\n",
    "\n",
    "valid_ds = pprfcnDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                         image_path = spatialsenses_pth/'images',\n",
    "                         split='valid',\n",
    "                         x_tfms = [transforms.ToPILImage(\"RGB\")],\n",
    "                         y_category_tfms = [map_spatialsenses_to_stupd])\n",
    "\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f75ac9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size =64 , shuffle = True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = 128 , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "823f880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "dls.n_inp = 3\n",
    "\n",
    "model = PPRFCN(train_ds.c, imagenet_pretrained = False).cuda()\n",
    "learn = Learner(dls, model = model, loss_func = CrossEntropyLossFlat(), metrics = [accuracy,BalancedAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ad1c9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.830299</td>\n",
       "      <td>1.724167</td>\n",
       "      <td>0.360121</td>\n",
       "      <td>0.248109</td>\n",
       "      <td>06:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.702148</td>\n",
       "      <td>1.648282</td>\n",
       "      <td>0.392722</td>\n",
       "      <td>0.302793</td>\n",
       "      <td>06:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.621165</td>\n",
       "      <td>1.591578</td>\n",
       "      <td>0.404094</td>\n",
       "      <td>0.302426</td>\n",
       "      <td>06:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.566635</td>\n",
       "      <td>1.590252</td>\n",
       "      <td>0.426839</td>\n",
       "      <td>0.313275</td>\n",
       "      <td>06:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.534065</td>\n",
       "      <td>1.586482</td>\n",
       "      <td>0.423048</td>\n",
       "      <td>0.315444</td>\n",
       "      <td>06:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c5c30e",
   "metadata": {},
   "source": [
    "# VTransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44b31983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.spatialsense.vtranseDataset import vtranseDataset\n",
    "from dataloaders.spatialsense.utils import  map_spatialsenses_to_stupd\n",
    "from models.static.vtranse import VtransE\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bec57aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 1319)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = vtranseDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                         image_path = spatialsenses_pth/'images',\n",
    "                          encoder_path = encoder_path, \n",
    "                         split='train',\n",
    "                         x_tfms = [transforms.ToPILImage(\"RGB\"),\n",
    "                                   transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
    "                                  ],\n",
    "                         y_category_tfms = [map_spatialsenses_to_stupd],\n",
    "                        )\n",
    "\n",
    "valid_ds = vtranseDataset(annotations_path = spatialsenses_pth/'annotations.json',\n",
    "                         image_path = spatialsenses_pth/'images',\n",
    "                          encoder_path = encoder_path, \n",
    "                         split='valid',\n",
    "                          x_category_tfms = None,\n",
    "    \n",
    "                         x_tfms = [transforms.ToPILImage(\"RGB\")],\n",
    "                         y_category_tfms = [map_spatialsenses_to_stupd])\n",
    "\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3c4f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size =64 , shuffle = True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = 128 , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a69c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "dls.n_inp = 7\n",
    "\n",
    "model = VtransE(word_embedding_dim = 300, num_classes = train_ds.c, imagenet_pretrained = False).cuda()\n",
    "learn = Learner(dls, model = model, loss_func = CrossEntropyLossFlat(), metrics = [accuracy,BalancedAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fd79525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.541802</td>\n",
       "      <td>1.447526</td>\n",
       "      <td>0.457165</td>\n",
       "      <td>0.336466</td>\n",
       "      <td>01:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.395959</td>\n",
       "      <td>1.362635</td>\n",
       "      <td>0.492798</td>\n",
       "      <td>0.405751</td>\n",
       "      <td>01:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.305874</td>\n",
       "      <td>1.321776</td>\n",
       "      <td>0.516300</td>\n",
       "      <td>0.436651</td>\n",
       "      <td>01:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.231300</td>\n",
       "      <td>1.351207</td>\n",
       "      <td>0.517817</td>\n",
       "      <td>0.439933</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.162749</td>\n",
       "      <td>1.351080</td>\n",
       "      <td>0.507961</td>\n",
       "      <td>0.435570</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
