{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3b6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b0e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastai.distributed import *\n",
    "from fastai.vision.all import *\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5edd0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "core_pth = Path('/home/agrawalp2/prepositions'); assert core_pth.exists()\n",
    "spatialSenses_pth = core_pth/Path('real_world_data/spatialsense'); assert spatialSenses_pth.exists()\n",
    "stupd_pth = Path('/mnt/dataset/agrawalp2/stupd_dataset'); assert stupd_pth.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5689f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from autocorrect import Speller\n",
    "\n",
    "encoder_path = spatialSenses_pth/Path('baselines/GoogleNews-vectors-negative300.bin.gz')\n",
    "assert encoder_path.exists()\n",
    "word2vec = KeyedVectors.load_word2vec_format(encoder_path, binary=True, unicode_errors=\"ignore\")\n",
    "\n",
    "spell = Speller()\n",
    "def phrase2vec(phrase, max_phrase_len, word_embedding_dim):\n",
    "    vec = np.zeros((max_phrase_len, word_embedding_dim,), dtype=np.float32)\n",
    "    for i, word in enumerate(phrase.split()[:max_phrase_len]):\n",
    "        if word in word2vec: vec[i] = word2vec[word]\n",
    "        elif spell(word) in word2vec: vec[i] = word2vec[spell(word)]\n",
    "        else: pass\n",
    "    return vec\n",
    "\n",
    "\n",
    "def read_img(url, imagepath):\n",
    "    if url.startswith(\"http\"):  # flickr\n",
    "        filename = os.path.join(imagepath, \"flickr\", url.split(\"/\")[-1])\n",
    "    else:  # nyu\n",
    "        filename = os.path.join(imagepath, \"nyu\", url.split(\"/\")[-1])\n",
    "    return filename\n",
    "#     img = cv2.imread(filename).astype(np.float32, copy=False)[:, :, ::-1]\n",
    "#     assert img.shape[2] == 3\n",
    "#     return img\n",
    "\n",
    "\n",
    "\n",
    "spatialsenses_to_stupd = {\n",
    "    \"above\": \"above\",\n",
    "    \"behind\": \"behind\",\n",
    "    \"in\": \"inside\",\n",
    "    \"in front of\": \"in_front_of\",\n",
    "    \"next to\": \"beside\",\n",
    "    \"on\": \"on\",\n",
    "    \"to the left of\": \"beside\",\n",
    "    \"to the right of\": \"beside\",\n",
    "    \"under\": \"below\",\n",
    "}\n",
    "\n",
    "\n",
    "def map_spatialsenses_to_stupd(o, mapping_dict = spatialsenses_to_stupd):\n",
    "    return spatialsenses_to_stupd[o]\n",
    "\n",
    "def noop(x): return x\n",
    "\n",
    "def convert_stupd_bbox_to_spatialsense_bbox(bbox):\n",
    "    #stupd bbox format = wmin, hmin, w, h\n",
    "    #spatialsenses bbox format = hmin, hmax, wmin, wmax\n",
    "    \n",
    "    wmin, hmin, w,h = bbox\n",
    "    return (hmin, hmin+h, wmin, wmin+w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f87bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialDataset(Dataset):\n",
    "    def __init__(self, split=None, \n",
    "                 annotations_path = spatialSenses_pth/'annotations.json', \n",
    "                 image_path = spatialSenses_pth/'images',\n",
    "                 x_category_tfms: list = None,\n",
    "                 y_category_tfms: list = None,\n",
    "                 x_img_tfms: list = None,\n",
    "                bbox_mask_tfms = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        assert Path(annotations_path).exists(), f'invalid annotations file path'\n",
    "        assert Path(image_path).exists(), f'invalid images directory path'\n",
    "        \n",
    "        self.subjects = [] #x1: subject classname\n",
    "        self.objects = [] #x2: object class name\n",
    "        \n",
    "        self.subj_bbox = []\n",
    "        self.obj_bbox = []\n",
    "        \n",
    "        self.predicates = [] #y: predicate (preposition) class name\n",
    "        \n",
    "        self.image_fnames = []\n",
    "        \n",
    "        \n",
    "        self.split = split\n",
    "        if self.split is not None: assert split in ['train', 'valid', 'test'], f\"invalid selection of split. expected values = 'train', 'valid', 'test'\"\n",
    "        \n",
    "        self.classes = list(set(spatialsenses_to_stupd.values()))\n",
    "        self.class2idx = {cat:i for i,cat in enumerate(self.classes)}\n",
    "        self.idx2class = {self.class2idx[cat]:cat for cat in self.class2idx}\n",
    "        self.c = len(self.classes)\n",
    "        \n",
    "        #transforms\n",
    "        self.x_category_tfms = list(x_category_tfms or [noop]) \n",
    "        self.y_category_tfms = list(y_category_tfms or [noop]) + [lambda y: self.class2idx[y]]\n",
    "        self.x_img_tfms = list(x_img_tfms or [noop]) + [transforms.ToTensor()]\n",
    "        self.bbox_mask_tfms = list(bbox_mask_tfms or [noop]) + [transforms.ToTensor()]\n",
    "        \n",
    "        #enumerating all raw data objects\n",
    "        for relations in json.load(open(annotations_path)):\n",
    "            if self.split and not relations[\"split\"] == split: continue\n",
    "            for relation in relations['annotations']:\n",
    "                if not relation['label']: continue\n",
    "                self.subjects.append(relation['subject']['name'])\n",
    "                self.objects.append(relation['object']['name'])\n",
    "                self.predicates.append(relation['predicate'])\n",
    "                \n",
    "                self.subj_bbox.append(relation['subject']['bbox'])\n",
    "                self.obj_bbox.append(relation['object']['bbox'])\n",
    "                \n",
    "                self.image_fnames.append(read_img(relations['url'], image_path))\n",
    "                \n",
    "    \n",
    "    def __len__(self): return len(self.subjects)\n",
    "    def __getitem__(self, i):\n",
    "        #for language part of the model\n",
    "        subj = self.apply_tfms(self.subjects[i], self.x_category_tfms)\n",
    "        obj =  self.apply_tfms(self.objects[i] , self.x_category_tfms)\n",
    "        predicate = self.apply_tfms(self.predicates[i], self.y_category_tfms)\n",
    "        \n",
    "        #for computer vision part of the model\n",
    "        img = Image.open(self.image_fnames[i])\n",
    "        ih,iw = img.shape\n",
    "        union_bbox = self.enlarge(self._getUnionBBox(self.subj_bbox[i], self.obj_bbox[i], ih, iw), 1.25, ih, iw)\n",
    "        bbox_img = self.apply_tfms(self._getAppr(np.array(img), union_bbox), self.x_img_tfms)\n",
    "        \n",
    "        bbox_mask = np.stack([self._getDualMask(ih, iw,self.subj_bbox[i], 32).astype(np.uint8),\n",
    "                              self._getDualMask(ih, iw, self.obj_bbox[i], 32).astype(np.uint8),\n",
    "                              np.zeros((32, 32), dtype=np.uint8)],\n",
    "                             2)\n",
    "        bbox_mask = self.apply_tfms(bbox_mask, self.bbox_mask_tfms)[:2].float() / 255.0\n",
    "    \n",
    "        \n",
    "        return (torch.Tensor(subj).type(torch.cuda.FloatTensor), \n",
    "                torch.Tensor(obj).type(torch.cuda.FloatTensor), \n",
    "                bbox_img.type(torch.cuda.FloatTensor),\n",
    "                bbox_mask.type(torch.cuda.FloatTensor),\n",
    "                torch.Tensor([predicate]).type(torch.cuda.LongTensor))\n",
    "\n",
    "    def apply_tfms(self, o, tfms):\n",
    "        for tfm in tfms: o = tfm(o)\n",
    "        return o\n",
    "    \n",
    "    \n",
    "    \n",
    "    def enlarge(self, bbox, factor, ih, iw):\n",
    "        height = bbox[1] - bbox[0]\n",
    "        width = bbox[3] - bbox[2]\n",
    "        assert height > 0 and width > 0\n",
    "        return [\n",
    "            max(0, int(bbox[0] - (factor - 1.0) * height / 2.0)),\n",
    "            min(ih, int(bbox[1] + (factor - 1.0) * height / 2.0)),\n",
    "            max(0, int(bbox[2] - (factor - 1.0) * width / 2.0)),\n",
    "            min(iw, int(bbox[3] + (factor - 1.0) * width / 2.0)),\n",
    "        ]\n",
    "\n",
    "    def _getAppr(self, im, bb, out_size=224.0):\n",
    "            subim = im[bb[0] : bb[1], bb[2] : bb[3], :]\n",
    "            subim = cv2.resize(\n",
    "                subim,\n",
    "                None,\n",
    "                None,\n",
    "                out_size / subim.shape[1],\n",
    "                out_size / subim.shape[0],\n",
    "                interpolation=cv2.INTER_LINEAR,\n",
    "            )\n",
    "            subim = (subim / 255.0 - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225] #mean and std of imagenet\n",
    "            return subim.astype(np.float32, copy=False)\n",
    "\n",
    "    def _getUnionBBox(self, aBB, bBB, ih, iw, margin=10):\n",
    "            return [max(0, min(aBB[0], bBB[0]) - margin),\n",
    "                    min(ih, max(aBB[1], bBB[1]) + margin),\n",
    "                    max(0, min(aBB[2], bBB[2]) - margin),\n",
    "                    min(iw, max(aBB[3], bBB[3]) + margin)]\n",
    "        \n",
    "    def _getDualMask(self, ih, iw, bb, heatmap_size=32):\n",
    "            rh = float(heatmap_size) / ih\n",
    "            rw = float(heatmap_size) / iw\n",
    "            x1 = max(0, int(math.floor(bb[0] * rh)))\n",
    "            x2 = min(heatmap_size, int(math.ceil(bb[1] * rh)))\n",
    "            y1 = max(0, int(math.floor(bb[2] * rw)))\n",
    "            y2 = min(heatmap_size, int(math.ceil(bb[3] * rw)))\n",
    "            mask = np.zeros((heatmap_size, heatmap_size), dtype=np.float32)\n",
    "            mask[x1:x2, y1:y2] = 255\n",
    "            return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ccd656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 1319)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_phrase_len = 2 #subjects/objects can be mutliple words. eg - microwave oven. max_phrase_len decides how many words are used to create embeddings\n",
    "word_embedding_dim = 300 #decides the dimension of the feature each word is converted into\n",
    "\n",
    "embedding = partial(phrase2vec, max_phrase_len = max_phrase_len, word_embedding_dim = word_embedding_dim)\n",
    "\n",
    "train_ds = SpatialDataset(split = 'train',\n",
    "                          x_category_tfms = [embedding],\n",
    "                          y_category_tfms = [map_spatialsenses_to_stupd],\n",
    "                          x_img_tfms =     [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.RandomResizedCrop(224, scale=(0.75, 0.85)),\n",
    "                                            transforms.ColorJitter(0.1, 0.1, 0.1, 0.05)],\n",
    "            \n",
    "                          bbox_mask_tfms = [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.Pad(4, padding_mode=\"edge\"),\n",
    "                                            transforms.RandomResizedCrop(32, scale=(0.75, 0.85))]\n",
    "                         )\n",
    "\n",
    "valid_ds = SpatialDataset(split = 'valid',\n",
    "                          x_category_tfms = [embedding],\n",
    "                          y_category_tfms = [map_spatialsenses_to_stupd],\n",
    "                          x_img_tfms =     [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.CenterCrop(224)],\n",
    "                          \n",
    "                          bbox_mask_tfms = [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.Pad(4, padding_mode=\"edge\"),\n",
    "                                            transforms.CenterCrop(32)]\n",
    "                         )\n",
    "\n",
    "len(train_ds),len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1abcf248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 300])\n",
      "torch.Size([2, 300])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([2, 32, 32])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for o in train_ds[0]: print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa8b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size =64 , shuffle = True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = 128 , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80bc00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper models\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, in_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels // 2, kernel_size=1)\n",
    "        self.layernorm1 = nn.LayerNorm((out_channels // 2, in_size, in_size))\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels // 2, out_channels // 2, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.layernorm2 = nn.LayerNorm((out_channels // 2, in_size, in_size))\n",
    "        self.conv3 = nn.Conv2d(out_channels // 2, out_channels, kernel_size=1)\n",
    "        self.conv_skip = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = F.relu(self.layernorm1(self.conv1(inp)))\n",
    "        x = F.relu(self.layernorm2(self.conv2(x)))\n",
    "        x = self.conv3(x)\n",
    "        return x + self.conv_skip(inp)\n",
    "\n",
    "class Hourglass(nn.Module):\n",
    "    def __init__(self, im_size, feature_dim):\n",
    "        super().__init__()\n",
    "        assert im_size == 1 or im_size % 2 == 0\n",
    "        self.skip_resblock = ResidualBlock(feature_dim, feature_dim, im_size)\n",
    "        if im_size > 1:\n",
    "            self.pre_resblock = ResidualBlock(feature_dim, feature_dim, im_size // 2)\n",
    "            self.layernorm1 = nn.LayerNorm((feature_dim, im_size // 2, im_size // 2))\n",
    "            self.sub_hourglass = Hourglass(im_size // 2, feature_dim)\n",
    "            self.layernorm2 = nn.LayerNorm((feature_dim, im_size // 2, im_size // 2))\n",
    "            self.post_resblock = ResidualBlock(feature_dim, feature_dim, im_size // 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        up = self.skip_resblock(x)\n",
    "        if x.size(-1) == 1:\n",
    "            return up\n",
    "        down = F.max_pool2d(x, 2)\n",
    "        down = F.relu(self.layernorm1(self.pre_resblock(down)))\n",
    "        down = F.relu(self.layernorm2(self.sub_hourglass(down)))\n",
    "        down = self.post_resblock(down)\n",
    "        down = F.upsample(down, scale_factor=2)\n",
    "        return up + down\n",
    "\n",
    "    \n",
    "    \n",
    "class PhraseEncoder(nn.Module):\n",
    "    def __init__(self, word_embedding_dim, num_layers = 1, batch_first = True, bidirectional = True):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.GRU(input_size = word_embedding_dim, \n",
    "                                     hidden_size = word_embedding_dim//2,\n",
    "                                     num_layers = num_layers,\n",
    "                                     batch_first = batch_first,\n",
    "                                     bidirectional = bidirectional,\n",
    "                                    )\n",
    "    def forward(self, x): return torch.squeeze(self.encoder(x)[0][:,-1,:])\n",
    "    \n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.batchnorm = nn.BatchNorm1d(output_dim)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.ReLU(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df87ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRNet(nn.Module):\n",
    "    def __init__(self, phrase_encoder, feature_dim, num_classes, num_layers=3, backbone='resnet18'):\n",
    "        super(DRNet, self).__init__()\n",
    "        \n",
    "\n",
    "        self.phrase_encoder =  phrase_encoder\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.appr_module = models.__dict__[backbone](pretrained=True)\n",
    "#         self.appr_module = backbone(pretrained = True)\n",
    "        self.appr_module.fc = nn.Linear(512, feature_dim//2)\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.c = num_classes\n",
    "\n",
    "        self.pos_module = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv1_p\", nn.Conv2d(2, 32, 5, 2, 2)),\n",
    "                    (\"batchnorm1_p\", nn.BatchNorm2d(32)),\n",
    "                    (\"relu1_p\", nn.ReLU()),\n",
    "                    (\"conv2_p\", nn.Conv2d(32, 64, 3, 1, 1)),\n",
    "                    (\"batchnorm2_p\", nn.BatchNorm2d(64)),\n",
    "                    (\"relu2_p\", nn.ReLU()),\n",
    "                    (\"maxpool2_p\", nn.MaxPool2d(2)),\n",
    "                    (\"hg\", Hourglass(8, 64)),\n",
    "                    (\"batchnorm_p\", nn.BatchNorm2d(64)),\n",
    "                    (\"relu_p\", nn.ReLU()),\n",
    "                    (\"maxpool_p\", nn.MaxPool2d(2)),\n",
    "                    (\"conv3_p\", nn.Conv2d(64, feature_dim//2, 4)),\n",
    "                    (\"batchnorm3_p\", nn.BatchNorm2d(feature_dim//2)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "#         self.PhiR_0 = nn.Linear(512, feature_dim)\n",
    "        self.batchnorm = nn.BatchNorm1d(feature_dim)\n",
    "\n",
    "        self.Phi_subj = nn.Linear(300, feature_dim//2)\n",
    "        self.Phi_obj = nn.Linear(300, feature_dim//2)\n",
    "#         self.PhiR = nn.Linear(feature_dim, feature_dim)\n",
    "\n",
    "#         self.fc = nn.Linear(feature_dim, 9)\n",
    "        self.fc = nn.Sequential(LinearBlock(2*feature_dim,feature_dim), \n",
    "                                LinearBlock(feature_dim, feature_dim//2), \n",
    "                                nn.Linear(feature_dim//2, self.c))\n",
    "\n",
    "    def forward(self, subj, obj, im, posdata):\n",
    "        appr_feature = self.appr_module(im) #output 256 features\n",
    "        pos_feature = (self.pos_module(posdata).view(-1, self.feature_dim//2))#output 256 features\n",
    "        \n",
    "        \n",
    "        qa = self.phrase_encoder(subj)\n",
    "        qb = self.phrase_encoder(obj)\n",
    "        \n",
    "        x = torch.cat([appr_feature, \n",
    "                       pos_feature,\n",
    "                       self.Phi_subj(qa), self.Phi_obj(qb),\n",
    "                      ], 1)\n",
    "\n",
    "#         qr = F.relu(self.batchnorm(self.PhiR_0(torch.cat([appr_feature, pos_feature], 1))))\n",
    "\n",
    "#         qa = self.phrase_encoder(subj)\n",
    "#         qb = self.phrase_encoder(obj)\n",
    "#         for i in range(self.num_layers):\n",
    "#             qr = F.relu(self.PhiA(qa) + self.PhiB(qb) + self.PhiR(qr))\n",
    "\n",
    "#         qr = self.fc(qr)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d6b05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "dls.n_inp = 4\n",
    "\n",
    "phrase_encoder = PhraseEncoder(300)\n",
    "model = model = DRNet(phrase_encoder, 512, train_ds.c).cuda()\n",
    "\n",
    "learn = Learner(dls, model = model, loss_func = CrossEntropyLossFlat(), metrics = [accuracy,BalancedAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f788acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.689916</td>\n",
       "      <td>1.712701</td>\n",
       "      <td>0.359363</td>\n",
       "      <td>0.221295</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.515124</td>\n",
       "      <td>1.463387</td>\n",
       "      <td>0.452616</td>\n",
       "      <td>0.327940</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.396506</td>\n",
       "      <td>1.383211</td>\n",
       "      <td>0.494314</td>\n",
       "      <td>0.387329</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.291989</td>\n",
       "      <td>1.391297</td>\n",
       "      <td>0.498105</td>\n",
       "      <td>0.396948</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.223384</td>\n",
       "      <td>1.365589</td>\n",
       "      <td>0.495072</td>\n",
       "      <td>0.425831</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.135480</td>\n",
       "      <td>1.364263</td>\n",
       "      <td>0.520849</td>\n",
       "      <td>0.443239</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.062435</td>\n",
       "      <td>1.349620</td>\n",
       "      <td>0.526914</td>\n",
       "      <td>0.461275</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.963906</td>\n",
       "      <td>1.379919</td>\n",
       "      <td>0.518575</td>\n",
       "      <td>0.449859</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.880227</td>\n",
       "      <td>1.382702</td>\n",
       "      <td>0.529189</td>\n",
       "      <td>0.459105</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.834297</td>\n",
       "      <td>1.381590</td>\n",
       "      <td>0.527672</td>\n",
       "      <td>0.455960</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a85148",
   "metadata": {},
   "source": [
    "# Pretraining on stupd now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "363842ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stupd(Dataset):\n",
    "    def __init__(self, \n",
    "                 annotations_path = stupd_pth/'annotations', \n",
    "                 image_path = stupd_pth/'stupd',\n",
    "                 x_category_tfms: list = None,\n",
    "                 y_category_tfms: list = None,\n",
    "                 x_img_tfms: list = None,\n",
    "                bbox_mask_tfms = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        assert Path(annotations_path).exists(), f'invalid annotations file path'\n",
    "        assert Path(image_path).exists(), f'invalid images directory path'\n",
    "        \n",
    "        self.subjects = [] #x1: subject classname\n",
    "        self.objects = [] #x2: object class name\n",
    "        \n",
    "        self.subj_bbox = []\n",
    "        self.obj_bbox = []\n",
    "        \n",
    "        self.predicates = [] #y: predicate (preposition) class name\n",
    "        \n",
    "        self.image_fnames = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.classes = list(set(spatialsenses_to_stupd.values()))\n",
    "        self.class2idx = {cat:i for i,cat in enumerate(self.classes)}\n",
    "        self.idx2class = {self.class2idx[cat]:cat for cat in self.class2idx}\n",
    "        self.c = len(self.classes)\n",
    "        \n",
    "        #transforms\n",
    "        self.x_category_tfms = list(x_category_tfms or [noop]) \n",
    "        self.y_category_tfms = list(y_category_tfms or [noop]) + [lambda y: self.class2idx[y]]\n",
    "        self.x_img_tfms = list(x_img_tfms or [noop]) + [transforms.ToTensor()]\n",
    "        self.bbox_mask_tfms = list(bbox_mask_tfms or [noop]) + [transforms.ToTensor()]\n",
    "        \n",
    "        #enumerating all raw data objects\n",
    "        for annotations in annotations_path.iterdir():\n",
    "            \n",
    "            if annotations.stem not in spatialsenses_to_stupd.values(): continue\n",
    "            df = pd.read_csv(annotations).dropna()\n",
    "            for i,row in df.iterrows():\n",
    "#                 self.subjects.append(relation['subject']['name'])\n",
    "#                 self.objects.append(relation['object']['name'])\n",
    "#                 self.predicates.append(relation['predicate'])\n",
    "                \n",
    "#                 self.subj_bbox.append(relation['subject']['bbox'])\n",
    "#                 self.obj_bbox.append(relation['object']['bbox'])\n",
    "                \n",
    "#                 self.image_fnames.append(read_img(relations['url'], image_path))\n",
    "                self.subjects.append(row['subject_category'] + ' ' + row['subject_supercategory'])\n",
    "                self.objects.append(row['object_category'] + ' ' + row['object_supercategory'])\n",
    "                self.predicates.append(annotations.stem)\n",
    "            \n",
    "                subj_2dbbox = ast.literal_eval(row['subject_bbox2d'])[0]\n",
    "                obj_2dbbox = ast.literal_eval(row['object_bbox2d'])[0]\n",
    "\n",
    "                self.subj_bbox.append(convert_stupd_bbox_to_spatialsense_bbox(subj_2dbbox))\n",
    "                self.obj_bbox.append(convert_stupd_bbox_to_spatialsense_bbox(obj_2dbbox))\n",
    "                \n",
    "                img_pth = ast.literal_eval(row['image_path'])[0]\n",
    "                self.image_fnames.append(image_path/img_pth)\n",
    "                \n",
    "    \n",
    "    def __len__(self): return len(self.subjects)\n",
    "    def __getitem__(self, i):\n",
    "        #for language part of the model\n",
    "        subj = self.apply_tfms(self.subjects[i], self.x_category_tfms)\n",
    "        obj =  self.apply_tfms(self.objects[i] , self.x_category_tfms)\n",
    "        predicate = self.apply_tfms(self.predicates[i], self.y_category_tfms)\n",
    "        \n",
    "        #for computer vision part of the model\n",
    "        img = Image.open(self.image_fnames[i])\n",
    "        ih,iw = img.shape\n",
    "        union_bbox = self.enlarge(self._getUnionBBox(self.subj_bbox[i], self.obj_bbox[i], ih, iw), 1.25, ih, iw)\n",
    "        bbox_img = self.apply_tfms(self._getAppr(np.array(img)[:,:,:3], union_bbox), self.x_img_tfms)\n",
    "        \n",
    "        bbox_mask = np.stack([self._getDualMask(ih, iw,self.subj_bbox[i], 32).astype(np.uint8),\n",
    "                              self._getDualMask(ih, iw, self.obj_bbox[i], 32).astype(np.uint8),\n",
    "                              np.zeros((32, 32), dtype=np.uint8)],\n",
    "                             2)\n",
    "        bbox_mask = self.apply_tfms(bbox_mask, self.bbox_mask_tfms)[:2].float() / 255.0\n",
    "    \n",
    "        \n",
    "        return (torch.Tensor(subj).type(torch.cuda.FloatTensor), \n",
    "                torch.Tensor(obj).type(torch.cuda.FloatTensor), \n",
    "                bbox_img.type(torch.cuda.FloatTensor),\n",
    "                bbox_mask.type(torch.cuda.FloatTensor),\n",
    "                torch.Tensor([predicate]).type(torch.cuda.LongTensor))\n",
    "\n",
    "    def apply_tfms(self, o, tfms):\n",
    "        for tfm in tfms: o = tfm(o)\n",
    "        return o\n",
    "    \n",
    "    \n",
    "    \n",
    "    def enlarge(self, bbox, factor, ih, iw):\n",
    "        height = bbox[1] - bbox[0]\n",
    "        width = bbox[3] - bbox[2]\n",
    "        assert height > 0 and width > 0\n",
    "        return [\n",
    "            max(0, int(bbox[0] - (factor - 1.0) * height / 2.0)),\n",
    "            min(ih, int(bbox[1] + (factor - 1.0) * height / 2.0)),\n",
    "            max(0, int(bbox[2] - (factor - 1.0) * width / 2.0)),\n",
    "            min(iw, int(bbox[3] + (factor - 1.0) * width / 2.0)),\n",
    "        ]\n",
    "\n",
    "    def _getAppr(self, im, bb, out_size=224.0):\n",
    "            subim = im[bb[0] : bb[1], bb[2] : bb[3], :]\n",
    "            subim = cv2.resize(\n",
    "                subim,\n",
    "                None,\n",
    "                None,\n",
    "                out_size / subim.shape[1],\n",
    "                out_size / subim.shape[0],\n",
    "                interpolation=cv2.INTER_LINEAR,\n",
    "            )\n",
    "            subim = (subim / 255.0 - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225] #mean and std of imagenet\n",
    "            return subim.astype(np.float32, copy=False)\n",
    "\n",
    "    def _getUnionBBox(self, aBB, bBB, ih, iw, margin=10):\n",
    "            return [max(0, min(aBB[0], bBB[0]) - margin),\n",
    "                    min(ih, max(aBB[1], bBB[1]) + margin),\n",
    "                    max(0, min(aBB[2], bBB[2]) - margin),\n",
    "                    min(iw, max(aBB[3], bBB[3]) + margin)]\n",
    "        \n",
    "    def _getDualMask(self, ih, iw, bb, heatmap_size=32):\n",
    "            rh = float(heatmap_size) / ih\n",
    "            rw = float(heatmap_size) / iw\n",
    "            x1 = max(0, int(math.floor(bb[0] * rh)))\n",
    "            x2 = min(heatmap_size, int(math.ceil(bb[1] * rh)))\n",
    "            y1 = max(0, int(math.floor(bb[2] * rw)))\n",
    "            y2 = min(heatmap_size, int(math.ceil(bb[3] * rw)))\n",
    "            mask = np.zeros((heatmap_size, heatmap_size), dtype=np.float32)\n",
    "            mask[x1:x2, y1:y2] = 255\n",
    "            return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0218428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34313"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_phrase_len = 3 #subjects/objects can be mutliple words. eg - microwave oven. max_phrase_len decides how many words are used to create embeddings\n",
    "word_embedding_dim = 300 #decides the dimension of the feature each word is converted into\n",
    "\n",
    "embedding = partial(phrase2vec, max_phrase_len = max_phrase_len, word_embedding_dim = word_embedding_dim)\n",
    "\n",
    "ds = stupd(\n",
    "                          x_category_tfms = [embedding],\n",
    "                          y_category_tfms = None,\n",
    "                          x_img_tfms =     [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.RandomResizedCrop(224, scale=(0.75, 0.85)),\n",
    "                                            transforms.ColorJitter(0.1, 0.1, 0.1, 0.05)],\n",
    "            \n",
    "                          bbox_mask_tfms = [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.Pad(4, padding_mode=\"edge\"),\n",
    "                                            transforms.RandomResizedCrop(32, scale=(0.75, 0.85))]\n",
    "                         )\n",
    "\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91fc8b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27450, 6863)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = 0.8\n",
    "train_ds, valid_ds = torch.utils.data.random_split(ds, [int(len(ds)*train_split), len(ds) - int(len(ds)*train_split)])\n",
    "train_ds.c, valid_ds.c = ds.c,ds.c\n",
    "\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e1de6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size =64 , shuffle = True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = 128 , shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53c71e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "dls.n_inp = 4\n",
    "\n",
    "phrase_encoder = PhraseEncoder(300)\n",
    "model = model = DRNet(phrase_encoder, 512, train_ds.c).cuda()\n",
    "\n",
    "learn = Learner(dls, model = model, loss_func = CrossEntropyLossFlat(), metrics = [accuracy,BalancedAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37b44683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.0008317637839354575)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuYUlEQVR4nO3dd3xV9f3H8dfnZhKyIGRAAoRAmAkzbBmCBepEUVGoE0Gc1bZWW1u1Vn+2ta11K3UrDgoOXGhRljI0ICPsMAIBQhKEkITsfH9/3ItFzCQ5OXd8no/HfUDOOffeNxfIO2d9v2KMQSmllO9y2B1AKaWUvbQIlFLKx2kRKKWUj9MiUEopH6dFoJRSPk6LQCmlfJy/VS8sIh2B14BYwABzjDGPn7aNAI8D5wIngGuNMevqet127dqZxMRESzIrpZS3Wrt2bb4xJrqmdZYVAVAJ/NoYs05EwoC1IvJfY8yWU7b5OZDsegwFnnX9WqvExETS09OtyqyUUl5JRLJqW2fZoSFjzKGTP90bYwqBrUD8aZtdBLxmnFYDkSLS3qpMSimlfqpFzhGISCIwAFhz2qp4YP8pX2fz07JQSillIcuLQERCgQXAHcaY42f4GrNEJF1E0vPy8po3oFJK+TgrzxEgIgE4S2CuMebdGjY5AHQ85esE17IfMcbMAeYApKWl6eBISqkaVVRUkJ2dTWlpqd1RbBMcHExCQgIBAQENfo6VVw0J8CKw1Rjzz1o2WwjcKiJv4zxJXGCMOWRVJqWUd8vOziYsLIzExESc34J8izGGI0eOkJ2dTZcuXRr8PCv3CEYCVwGbRGS9a9nvgU4AxpjngE9wXjqaifPy0esszKOU8nKlpaU+WwIAIkJUVBSNPYRuWREYY74C6vzbMM4xsG+xKsOpjhaXs3xnHuf37YCfwzf/kSjlC3y1BE46kz+/z9xZvHxnHr98ez2bDhTYHUUppX4QGhoKwN69e0lJSbElg88UwajkaERg6fZcu6MopdzFxnnwWAo8EOn8deM8uxPZwmeKoG3rQPolRLJsh/tdflpZVU1eYdlPlldVGzIOFFBUVmlDKqW83MZ58OHtULAfMM5fP7y9yWVwzz338PTTT//w9QMPPMBDDz3E+PHjGThwIKmpqXzwwQd1vkZVVRV33XUXgwcPpm/fvjz//PMAXH311bz//vs/bDd9+vR6X6shLL181N2M6R7NE1/u5GhxOW1aBzbb62bmFpJfVM6wpKhGPS+vsIx3vt3H3DX7OFRQSpd2rRmd3I7UhEi+2XOExVtz+b64nNjwIB68KIWJfeJ+8hqlFVWs2nWETQcK6N0+nCFJbQkPDuD74nI+2niQD9Yf5EhRGeGtAohoFUDb1oEktGlFxzYhdGwbQmx4MHERwYQGNe6fQn5RGZ9m5LDvSDEHC0o5XFBKu9AgBnVuw8DOkaTERxDk79eo11SqRX3xIFSU/HhZRYlzed/Lz/hlp06dyh133MEttzhPf86bN4/PPvuM22+/nfDwcPLz8xk2bBgXXnhhrcfzX3zxRSIiIvj2228pKytj5MiRTJgwgRkzZvDYY48xefJkCgoKWLlyJa+++uoZZz3Jp4pgbI9oHv9iJysy87mwX4dmec33vzvA3Qs2UlZZzYTesfzx/N50bBvyo23KKqv4cmsuH208RG5hKZXVhsoqw7ac41RUGUYlt+Oq4Z35Zs/3vJO+n1dXZREW5M+4XjEMT4rilZV7ufH1tUzsE8tlgzqSW1hGTkEJWw4d56vMfEorqn94L4dAckwYu/KKqKw29IwLIzUhksLSCgpKKth7pJiPNh6iqvrHt2OEBvnTITKYDpGtiI9sRXllNdlHS8g+dgJBSEtsw7CkKKLDgpi/NpvPN+dQUWUIDnDQIaIVMeFBbDl0nEWbcwBoFeDHWcntGNczhvE9Y4gJD26Wz1upZlOQ3bjlDTRgwAByc3M5ePAgeXl5tGnThri4OO68806WL1+Ow+HgwIEDHD58mLi4n/5wB/D555+zceNG5s+f74xUUMDOnTuZMGECN998M3l5eSxYsIApU6bg79/0b+M+VQR9EyJpExLA0u25TS6CyqpqHvl0Gy9+tYehXdpyVrd2PLN0Fz97bBnTh3YmNMifsspq8ovK+O+WwxSUVBAdFkS36FCCAwR/h3DVsESmD+tE12jnyaKbxzp/wt+dV0y3mFAC/Z1H7qYMSuCFFXv41+IdfLb5MAAi0KltCFPTOjKuVywDOkWy+cBxVu0+wnf7jjK6ezsuHpBA7w7hNWY/VFBK9tESDh8vJed4KTkFpRw8VsKBYyVs2H+MQH8HCW1CGNSpDaUV1Szdnse765z3+kW0CuCqYYlcOaQj3WJCf/RTTV5hGWuzjvJ1Zj5fbsvlv1sO4xCY0DuOa0YkMiyprc9f1aHcRESC67BQDcub6LLLLmP+/Pnk5OQwdepU5s6dS15eHmvXriUgIIDExMQ6b3ozxvDkk08yceLEn6y7+uqreeONN3j77bd5+eWXm5wVfKwI/BzCqORolu/Io7ra4GjEZaQFJyp4ddVe9n9/gvyiMvYeOcGe/GKuHZHIvef1IsDPwSWDEnjooy28+NUeAAL9HbQO9OPsHtFcPDCBkV2j8Per+7RMcIDfT755B/g5uGlsVy4ZGM+BYyW0jwgmOjToJ681vGsUw7vWf3jK389Bx7YhP9lzqYsxhp25RRw4WsLwrlEEB9R82Cc6LIhJKXFMSonjQWPYcbiI99cf4O1v9rFocw49YsM4u2cMgxPbkNa5LREhDb/7UalmNf4+5zmBUw8PBbRyLm+iqVOnMnPmTPLz81m2bBnz5s0jJiaGgIAAlixZQlZWrQOBAjBx4kSeffZZxo0bR0BAADt27CA+Pp7WrVtz7bXXMmTIEOLi4ujdu3eTs4KPFQE4zxMs3HCQLYeOkxIfUe/2xhg+3nSIBxZu4UhxGXHhwUSFBtI5KoQ7zknmov7/GyMvPrIVz/5iEOWV1fg7pFFF0xCx4cHE2nSIRUToHhtG99iwRj2nR1wYd0/qyS/HJ7Nw/UHeSd/Pi1/t5rllzkNTPWLDGNylDYMT2zIqOZq2zXjuRqk6nTwP8MWDzsNBEQnOEmjC+YGT+vTpQ2FhIfHx8bRv357p06dzwQUXkJqaSlpaGj179qzz+TfccAN79+5l4MCBGGOIjo7+4SRxbGwsvXr1YvLkyU3OeZI47+nyHGlpaaYp8xHkFZYx+OHF/GZCd24dl1zntkeLy7lr/gYWb80lNT6CRy5JbVB5qLqVlFexIfsY3+75nm/2fs+6rKMUl1cREujHDaOSmDU6qdEnr5UC2Lp1K7169bI7hqVOnDhBamoq69atIyKi5u9HNX0OIrLWGJNW0/Y+978tOiyIlPhwlu3Iq7MIjDHcNX8Dy3fkc++5vbhuZGK9h3VUw7QK9GNYUtQPV1lVVlWTcfA4/16+mye+2Mnc1Vn88pxkpg3ppJ+5UqdYvHgxM2bM4M4776y1BM6ET/4vG9s9hnX7jlFQUlHrNu98u5/FW3O5++c9mTk6Sb8hWcjfz0H/jpE8PX0g798ykuTYUO77YDPnPfEVKzPz7Y6nlNs455xzyMrK4o477mjW1/XJ725jekRTVW0Y9/elDH54MQP//F9ueXMduYXOs/j7jpzgzx9tYUTXKK4bkWhvWB/Tv2Mkb80cxvNXDeJERSXTXljD7NfXknWk2O5oSnktnzs0BDCwUxtuGtuVI0Vl+DkcVFRVs3DDQb7OzOeP5/XmrW/24RDh0cv6NfsJX1U/EWFinzjGdI/mhRW7eXrJLr7Ydpirhydy27huRIboCWVVO2OMT1+ifCbnfX3uZHFtMnML+e38jazbdwyAx6b24+IBTb+eWDXd4eOlPPbfHcxL309okD//d0kq5/dtnhsClXfZs2cPYWFhREVF+WQZnJyPoLCw8CfzEdR1sliL4BRV1YY3VmdRUFLBbeO6+eQ/JHe2Lec4976Xwdqso/zx/N7MOKvhE28o36AzlNU+Q5kWgfIapRVV3PnOej7NyGHW6CTumdRTD98p1QB1FYFPnixWnis4wI+npg3k6uGdmbN8N3e8s57Siiq7Yynl0XzyZLHybH4O4U8X9iEuIpi/LdrOgWMlPH/VINqFBtkdTSmPpHsEyiOJCDeP7cYz0wey+WABk5/+mh2HC+2OpZRH0iJQHu3c1Pa8M2s4ZZXVTH76a175eg/V1Z513kspu2kRKI/Xr2MkC28dSVpiWx74cAuXP7+KzNwiu2Mp5TEsKwIReUlEckUko5b1bUTkPRHZKCLfiIg9szYrr9A+ohWvXjeYf1zWj525RZz7xApeXbn3jG6uUcrXWLlH8AowqY71vwfWG2P6AlcDj1uYRfkAEWHKoAQW/2oMI7tGcf/Czdz4+lqOnSi3O5pSbs2yIjDGLAe+r2OT3sCXrm23AYkiEmtVHuU7osOCePGawfzhvF4s2Z7LuY+vYMP+Y3bHUspt2XmOYANwCYCIDAE6AzWO6SAis0QkXUTS8/LyWjCi8lQOh3DDqCQW3DQCh0O4Ys5qlmzPtTuWUm7JziL4CxApIuuB24DvgBrvDDLGzDHGpBlj0qKjo1swovJ0fRMieffmEXRp15qZr6azYG3TJiZXyhvZVgTGmOPGmOuMMf1xniOIBnbblUd5r5iwYN65cRhDurTl1//ZwNNLMvUkslKnsK0IRCRSRE6OJ3wDsNwYc9yuPMq7hQUH8PJ1g7mofwce/Ww7N89dR1FZpd2xlHILlg0xISJvAWOBdiKSDdwPBAAYY54DegGviogBNgMzrMqiFECQvx//mtqflA4RPPLpVjJzi3j+qkEkRYfaHU0pW+noo8onrczM59a3vkOAz+4creMUKa+no48qdZoR3drx1sxhHC+t4IGFm+2Oo5SttAiUz+oRF8bt45L5aOMhFmXk2B1HKdtoESifNntsV3q3D+cP72foHcjKZ2kRKJ8W4Ofg0cv6cuxEOQ9+tMXuOErZQotA+bw+HSK4aWxX3l13gC+2HrY7jlItTotAKeDWcd3oGRfGPe9u0kNEyudoESiF8x6Dv1/Wj6PF5dyvVxEpH6NFoJRLSnwEt47rxgfrD7Io45DdcZRqMVoESp3ilrO7kRIfzr3vZZBfVGZ3HKVahBaBUqcI8HPwj8v6U1hayZ8+1KuIlG/QIlDqND3iwrj57K58uOEgS7bpHAbK+2kRKFWDm8Z2pVtMKH94P4NiHaVUeTktAqVqEOTvx18uSeXAsRL+/vl2u+MoZSktAqVqkZbYll8M68QrK/fy3b6jdsdRyjJaBErV4beTehITFsTv3t1EeWW13XGUsoQWgVJ1CA8O4KHJqWzLKeT5ZbvsjqOUJbQIlKrHz3rHcl7f9jz5ZSaZuYV2x1Gq2WkRKNUAD1zQh1aBftyzYBPV1Z41q59S9dEiUKoBosOC+OP5vUnPOsrcNVl2x1GqWWkRKNVAUwbGMyq5HX9dtJ3Dx0vtjqNUs7GsCETkJRHJFZGMWtZHiMiHIrJBRDaLyHVWZVGqOYgID01OobyqWiexUV7Fyj2CV4BJday/BdhijOkHjAX+ISKBFuZRqsk6R7Xm1rO78fHGQyzfkWd3HKWahWVFYIxZDnxf1yZAmIgIEOraVu/lV27vxjFJJLVrzX0fZFBaUWV3HKWazM5zBE8BvYCDwCbgl8YYvWNHub0gfz/+PDmFvUdO8OxSvbdAeT47i2AisB7oAPQHnhKR8Jo2FJFZIpIuIul5ebo7ruw3sls7LuzXgWeX7uLAsRK74yjVJHYWwXXAu8YpE9gD9KxpQ2PMHGNMmjEmLTo6ukVDKlWb307qQZUxvLhij91RlGoSO4tgHzAeQERigR7AbhvzKNUoCW1CuLBfB97+dp9OeK88mpWXj74FrAJ6iEi2iMwQkdkiMtu1yZ+BESKyCfgCuNsYk29VHqWscOOYJE6UV/HaKr3JTHkuf6te2BhzZT3rDwITrHp/pVpCz7hwxvWM4ZWVe5k5KolWgX52R1Kq0fTOYqWaaPaYrnxfXM5/1u63O4pSZ0SLQKkmGpzYhoGdIpmzfDeVVXoFtPI8WgRKNZGIMHtMV7KPlvDhxoN2x1Gq0bQIlGoG5/SKpWdcGE9+kUmVDlOtPIwWgVLNwOEQfjk+md35xXy4QfcKlGfRIlCqmUzsE0fPuDCe+GKn7hUoj6JFoFQzcTiEO87RvQLlebQIlGpGE3rrXoHyPFoESjUj515Bd3bnF/PB+gN2x1GqQbQIlGpmE3rHkhofwV8XbaOoTKfYUO5Pi0CpZuZwCH+enEJuYRn//HyH3XGUqpdlYw0p5cv6d4xk+tBOfL/6dcq3f0Bg0UGISIDx90Hfy+2Op9SPaBEoZZHfJ2Qg618gsMg1RHXBfvjwdufvtQyUG9FDQ0pZJGTFw7TitHkKKkrgiwftCaRULbQIlLJKQXbjlitlEy0CpawSkdC45UrZRItAKauMvw8CWv1oUZVfK+dypdyIFoFSVul7OVzwBER0xCDkEM3fAm+ios+ldidT6kf0qiGlrNT3cuh7OQJs2nKY519Lp93Xe5k5OsnuZEr9QPcIlGohP+sdy/ieMfxr8Q6OFpfX/wSlWogWgVIt6O6f96S4vIo3v9lndxSlfmBZEYjISyKSKyIZtay/S0TWux4ZIlIlIm2tyqOUO+geG8ao5Ha8tmovFTq/sXITVu4RvAJMqm2lMeZRY0x/Y0x/4HfAMmPM9xbmUcotXH9WFw4fL+OTTYfsjqIUYGERGGOWAw39xn4l8JZVWZRyJ2OSo0mKbs2LX+3BGJ2zQNnP9nMEIhKCc89hQR3bzBKRdBFJz8vLa7lwSlnA4RCuG9mFjdkFrNt31O44StlfBMAFwNd1HRYyxswxxqQZY9Kio6NbMJpS1pgyMJ6IVgG8+NUeu6Mo5RZFcAV6WEj5mJBAf64c0olFGTns//6E3XGUj7O1CEQkAhgDfGBnDqXscM2Izvg7HDy9JNPuKMrHWXn56FvAKqCHiGSLyAwRmS0is0/Z7GLgc2NMsVU5lHJX7SNaMX1YJ/6zNpvdeUV2x1E+TDztqoW0tDSTnp5udwylmkVeYRljHl3CuJ4xPDVtoN1xlBcTkbXGmLSa1rnDOQKlfFZ0WBDXj+zCRxsPsflggd1xlI/SIlDKZjNHJxHRKoB/6ET3yiYNKgIRaS0iDtfvu4vIhSISYG00pXxDRKsAZo/pypfbcknfqzfXq5bX0D2C5UCwiMQDnwNX4RxCQinVDK4dkUhMWBAPfLiZSh2DSLWwhhaBGGNOAJcAzxhjLgP6WBdLKd/SKtCP+y7oTcaB47y2KsvuOMrHNLgIRGQ4MB342LXMz5pISvmm81LbM6Z7NP/4fDuHCkrsjqN8SEOL4A6cI4S+Z4zZLCJJwBLLUinlg0SEP1+UQmW14U8Lt9gdR/mQBhWBMWaZMeZCY8xfXSeN840xt1ucTSmf0ykqhNvHJ7Nocw5fbD1sdxzlIxp61dCbIhIuIq2BDGCLiNxlbTSlfNPMUUkkx4TyyKfbdJhq1SIaemiotzHmODAZ+BTogvPKIaVUMwv0dzBzdBKZuUV8s0cvJ1XWa2gRBLjuG5gMLDTGVAD6o4pSFrmgbwfCgv2Zu0bnNlbWa2gRPA/sBVoDy0WkM3DcqlBK+bpWgX5MGZjAoowcvi8utzuO8nINPVn8hDEm3hhzrnHKAs62OJtSPm3a0E6UV1Uzf+1+u6MoL9fQk8URIvLPk9NFisg/cO4dKKUs0j02jMGJbXhzzT6qq/VIrLJOQw8NvQQUApe7HseBl60KpZRymja0E3uPnGDV7iN2R1FerKFF0NUYc78xZrfr8ScgycpgSin4eUp7IkMCeFNPGisLNbQISkTkrJNfiMhIQO+BV8piwQF+XDowgc8253D4eKndcZSXamgRzAaeFpG9IrIXeAq40bJUSqkfXDW8M1XG8NqqvXZHUV6qoVcNbTDG9AP6An2NMQOAcZYmU0oB0DmqNT/rFcvcNfsoKa+yO47yQo2aocwYc9x1hzHAryzIo5SqwYyzunDsRAXvfpdtdxTlhZoyVaXUuVLkJRHJFZGMOrYZKyLrRWSziCxrQhalvNqQLm1JiQ/npa/26KWkqtk1pQjq+9f4CjCptpUiEgk8A1xojOkDXNaELEp5NRFhxlld2JVXzLKdeXbHUV6mziIQkUIROV7DoxDoUNdzjTHLgbpGzJoGvGuM2efaPrex4ZXyJeeldiAmLIiXvtpjdxTlZeosAmNMmDEmvIZHmDHGv4nv3R1oIyJLRWStiFzdxNdTyqsF+ju4ZkQiK3bms/WQDvWlmk9TDg01lT8wCDgPmAj8UUS617ShiMw6ObxFXp7uFivfNX1oJ1oH+vHcsl12R1FexM4iyAY+M8YUG2PygeVAv5o2NMbMMcakGWPSoqOjWzSkUu4kMiSQ6cM68+GGg2QdKbY7jvISdhbBB8BZIuIvIiHAUGCrjXmU8gg3nNUFfz+H7hWoZmNZEYjIW8AqoIeIZIvIDBGZLSKzAYwxW4FFwEbgG+AFY0ytl5oqpZxiwoO5PC2B+WuzySnQYSdU0zX1hG+tjDFXNmCbR4FHrcqglLe6cXRX3vpmP/9esZs/nt/b7jjKw9l5aEgpdYY6tg3hon4deHPNPp3BTDWZFoFSHuqmsV0prazS+wpUk2kRKOWhkmPD+HlKHK+u3EvBiQq74ygPpkWglAe79exkCssqeXml7hWoM6dFoJQH690hnJ/1juWlr/ZQWKp7BerMaBEo5eFuH5fM8dJKXluVZXcU5aG0CJTycKkJEYzrGcMLK3ZTXFZpdxzlgbQIlPICt43rxtETFby+WvcKVONpESjlBQZ0asOY7tE8u3QXR/W+AtVIWgRKeYnfn9uLwtIKHv9ip91RlIfRIlDKS/SIC2Pa0E68vjqLzNxCu+MoD6JFoJQXufOc7oQE+vHQxzqQr2o4LQKlvEhUaBC/HJ/M0u15LNmus7+qhtEiUMrLXD08kcSoEB7+eCvV1cbuOMoDaBEo5WUC/R3c+bPuZOYWsWyHTu2q6qdFoJQXOje1PTFhQbyycq/dUZQH0CJQygsF+DmYPrQzy3bksTuvyO44ys1pESjlpa4c2pEAP9ExiFS9tAiU8lIxYcGcm9qeBWuzKdIxiFQdtAiU8mLXjEiksKyS99Zl2x1FuTEtAqW82ICOkfRNiODVVVkYo5eSerIjRWXkFZZZ8tqWFYGIvCQiuSKSUcv6sSJSICLrXY/7rMqilK8SEa4dkUhmbhFLt+ulpJ6kvLKaRRmHuO+DDCY8toxBDy3m5a+tmYnO35JXdXoFeAp4rY5tVhhjzrcwg1I+7/y+HfjH5zt4/IudjO0RjYjYHUnVobSiine+3c/zy3ZxsKCUkEA/0hLbMnlAPON6xljynpYVgTFmuYgkWvX6SqmGCfR3cPPZXbn3vQy+ysxnVHK03ZFUDYwxvPfdAf7vk63kF5WT1rkND12cwqjkaAL8rD2Kb/c5guEiskFEPhWRPrVtJCKzRCRdRNLz8nT3VqnGunRQAu0jgnl88U49V+CGCkoquP3t9fxq3gY6R7XmnVnDmH/TCMb1jLW8BMDeIlgHdDbG9AOeBN6vbUNjzBxjTJoxJi06Wn+aUaqxgvz9uGlsV9KzjrJq9xG746hTrN9/jHMfX8Enmw5x18QezLtxOEOTolo0g21FYIw5bowpcv3+EyBARNrZlUcpb3d5WkdiwoJ4QieucRvlldXc+uY6ABbcNIJbzu6Gn6Plz+HYVgQiEieus1YiMsSVRX9UUcoiwQF+zB7TldW7v2eN7hW4hXe+3Uf20RIevjiF/h0jbcth5eWjbwGrgB4iki0iM0RktojMdm1yKZAhIhuAJ4ArjB68VMpS04Z2ol1oEE8tybQ7is8rKa/iyS8zGZLYljHd7T3kbeVVQ1fWs/4pnJeXKqVaSHCAHzNHdeGRT7fx3b6jDOjUxu5IPuu1VXvJLSzjqWkDbb+k1+6rhpRSLWz6sM5EhgTwtO4V2OZ4aQXPLtvFmO7RDOnS1u44WgRK+ZrQIH+uH9mFxVtz2XywwO44Punfy3dz7EQFv5nQw+4ogBaBUj7pmhGJhAX588ySXXZH8RmlFVW89102Fz/zNU9+mcl5qe1JTYiwOxZg7RATSik3FdEqgGtGJPL00kwycwvpFhNmdySvVVZZxdzV+3h6SSZHistJatea+87vzRVDOtod7QdaBEr5qOvP6sKLX+3hmSW7+OfU/nbH8TrV1YYPNx7k0c+2k320hBFdo7h5bDdGdI3CYcO9AnXRIlDKR7VtHcgVQzry+qosfjOxBx0iW9kdyWvsOFzI79/dRHrWUXq3D+e161MZldzO9quDaqPnCJTyYdeP7IIBneS+mZRWVPH3z7Zz3hMryMwr4m9T+vLRbWcxurt7j/qqewRK+bCObUM4N7U9b67Zx63juhEeHGB3JI+1MfsYd76znl15xVwyIJ57z+tFVGiQ3bEaRPcIlPJxs0YlUVRWyTvf7Lc7ikeqrKrm8cU7ueSZlRSXVfHa9UP459T+HlMCoEWglM9LTYhgeFIUL329h4qqarvjeJSqasO1L3/LY4t3cF7f9nx2x2hG2zxcxJnQIlBKMWt0EocKSvlo40G7o3iUuWuy+Coznz9d2IfHrxhARIhnHlrTIlBKMaZ7NMkxoTy3dLfuFTRQTkEpf1u0nVHJ7bh6eGe74zSJFoFSCodD+PWE7mw/XMhzS/Vu44Z4YOFmKqqqeWhyiltfEdQQWgRKKQAmpbTngn4deOLLnWw5eNzuOG7tv1sOs2hzDrePT6ZzVGu74zSZFoFS6gcPXtiHyJBAfjVvPeWVeoioJjsPF3LfBxn0iA1j1ugku+M0Cy0CpdQP2rQO5C+XpLItp5Anv9QpLU9VVW2Ys3wX5z35FWWV1Tx6Wd8WmVi+JegNZUqpHxnfK5ZLByXwzNJdTOgd5zYjZNqloqqarzPzeerLTNKzjjKhdywPX5xKdJjn3CdQHy0CpdRP/PH83izfkcfdCzbywa0jveYn38bIOlLMv1fs5pNNOXxfXE5kSACPTe3H5P7xHn9y+HRaBEqpn4hoFcCDF6Uw+421vLBiDzeN7Wp3pBa143Ah0/69mqKySsb3iuWifh0Y0yOaIH8/u6NZQotAKVWjSSlxTOoTx78W72BSShxd2nn+1TENsT3HWQIOh/DRbaPoFhNqdyTLWba/JyIviUiuiGTUs91gEakUkUutyqKUOjN/uqgPgf4O7lmwkepqY3ccy23KLmDav1fj5xDenjXMJ0oArN0jeAV4Cnittg1ExA/4K/C5hTmUUmcoNjyYe8/txT3vbuLiZ1dyUb8OnNe3PbHhwXZHazZLtuXyyaZDrN5zhP3flxAbHsRbM4eRFO0bJQAWFoExZrmIJNaz2W3AAmCwVTmUUk0zdXBHSiqqmL82mwc/2sKfP97Cned05/bxyXZHa7Kth45z3SvfEhkSwNAubbl+ZBfOTfWuomsI284RiEg8cDFwNloESrktEeG6kV24bmQXduUV8ddPt/H4FzuZlBJH91jPnuv4jdVZBPk7WPqbsUSGBNodxzZ2XhP2L+BuY0y9ty+KyCwRSReR9Ly8POuTKaVq1DU6lL9M6UtokD8PLNyMMZ573qCwtIL3vzvABf06+HQJgL1FkAa8LSJ7gUuBZ0Rkck0bGmPmGGPSjDFp0dGeN9a3Ut6kbetAfjOhOyt3HeGTTTl2xzlj7393gOLyKn4xzLNHDm0OthWBMaaLMSbRGJMIzAduNsa8b1cepVTDTRvamd7tw3n44y2cKK+0O06jGWN4Y/U+UuLD6efjd06DtZePvgWsAnqISLaIzBCR2SIy26r3VEq1DD+H8KeL+nDQNSa/p81hkJ51lO2HC/nF0M5ed5fwmbDyqqErG7HttVblUEpZY3BiW6amdeSVlXv5NOMQVw9PZNqQTrRp7f7H299YnUVYsD8X9u9gdxS34HsDiCilms0jl6Ty8rWD6R4bxqOfbWfoI19w65vrWLo9lyo3vQEt40ABn27KYcrABEICdXAF0CEmlFJN4HAIZ/eM4eyeMWzPKWTumiwWbjjIRxsP0S40iA6RwQT7+xEU4KCiqprC0kqKyioZ2KkNf7u05YZxLq+s5sMNB5m7Jot1+47ROtDP46eXbE7iaZd/paWlmfT0dLtjKKVqUVZZxZJtuSzKyOFYSQWlFVWUVlQT6OcgLNgfEWHx1sNcM7wzf7ooxfI85ZXVzHj1W1bszCepXWumDe3ElIEJHnEIqzmJyFpjTFpN63SPQCnVrIL8/ZiU0p5JKe1r3eb/PtnKnOW7SY4Ns/Tyzepqw2/nb2DFznwempzC9KGd9ORwDfQcgVKqxd09qSfjesZw/8LNrMzMt+x9Hvl0K++vP8hdE3vwi2F6hVBttAiUUi3OzyE8fkV/ktq15sY31rJkW26zv8fLX+/h3yv2cM3wztzsY/MpNJYWgVLKFmHBAbx83WDiI1tx3Svf8rdF26hspvsRyiqr+NfinYzuHs19F/TRPYF6aBEopWyT0CaE928ZyRWDO/LM0l1Me2ENOQWlTX7dL7fmUlBSwYyzuuDn0BKojxaBUspWwQF+/GVKXx6b2o+MAwVM/NdyPt10qEmvuWBdNrHhQZzVrV0zpfRuWgRKKbdw8YAEPr59FIlRIdw0dx13/WcDxWWNH8cov6iMpdvzmDwgXvcGGkiLQCnlNrq0a838m0Zw69ndmL8um6teXNPoMli4/iCV1YYpAxMsSul9tAiUUm4lwM/Bbyb24JlpA9mQXcANr6ZTWlHV4OcvWJdNanyEx0+a05K0CJRSbunnqe35+2V9Wb3nCDe9sZbyyvqvKNqWc5zNB48zZWB8CyT0HloESim3dfGABB6enMqS7Xn88u3v6h3IbsHabPwdwgX9dFTRxtAiUEq5tWlDO/GH83rxaUYOv393U63TY5ZVVvH++oOc3TOGqNCgFk7p2XSsIaWU27thVBLHSyp44stMIkIC+N3Pe/7kJrG3v9lPXmGZjip6BrQIlFIe4c6fdedYSQVzlu8molUAt5zd7Yd1J8orefLLTIZ2aav3DpwBLQKllEcQER64oA8FJRU8+tl24sKDmTLIeYnoqyuzyC8q47lfDNThJM6AFoFSymM4HMKjl/Yj93gZ97y7kQ6RregTH85zy3Zxdo9o0hLb2h3RI+nJYqWURwn0d/DcVYNIjGrNja+nc/8HmykoqeDXE3rYHc1jaREopTxORKsAXrp2MIH+frz33QHOTY0jJT7C7lgey7IiEJGXRCRXRDJqWX+RiGwUkfUiki4iZ1mVRSnlfTq2DeGla9MY2S2Kuyb2tDuOR7NszmIRGQ0UAa8ZY34yMamIhALFxhgjIn2BecaYev82dc5ipZRqvLrmLLZsj8AYsxz4vo71ReZ/LdQasKaRlFJK1cnWcwQicrGIbAM+Bq6vY7tZrsNH6Xl5eS0XUCmlfICtRWCMec91OGgy8Oc6tptjjEkzxqRFR0e3WD6llPIFbnHVkOswUpKI6C2BSinVwmwrAhHpJq5bAEVkIBAEHLErj1JK+SrL7iwWkbeAsUA7EckG7gcCAIwxzwFTgKtFpAIoAaYaqy5hUkopVSvLisAYc2U96/8K/NWq91dKKdUwbnGOQCmllH0su6HMKiKSB2S5vowACur4/enLAoD8Rr7lqa/RkHWnL2toxpO/tmtkxpbKd3KZfobulc8TMrp7vqZkrGuZu32GnY0xNV92aYzx2Acwp67fn74MSG/KezRk3enLGprxlF8blbGl8uln6J75PCGju+drSsZ6srrVZ1jXw9MPDX1Yz+9rW3+m79GQdacva2hGd89X33vVRT/D+t+nLvU9z90zunu+2tY3JGN9yxrD6s+wVh53aKgpRCTd1DLWhrtw94zung/cP6O75wP3z+ju+cAzMp7k6XsEjTXH7gAN4O4Z3T0fuH9Gd88H7p/R3fOBZ2QEfGyPQCml1E/52h6BUkqp02gRKKWUj9MiUEopH6dF4CIio0TkORF5QURW2p2nJiLiEJGHReRJEbnG7jynE5GxIrLC9TmOtTtPTUSktWtui/PtzlITEenl+vzmi8hNduepiYhMFpF/i8g7IjLB7jynE5EkEXlRRObbneUk17+7V12f23S785zOK4qgtvmRRWSSiGwXkUwRuaeu1zDGrDDGzAY+Al51x4zARUACUAFku2E+g3N60mA3zQdwNzCvObM1Z0ZjzFbXv8PLgZFumvF9Y8xMYDYw1Q3z7TbGzGjOXDVpZNZLgPmuz+1Cq7M1WmPufHPXBzAaGAhknLLMD9gFJAGBwAagN5CK85v9qY+YU543Dwhzx4zAPcCNrufOd8N8DtfzYoG5bpjvZ8AVwLXA+e74d+x6zoXAp8A0d83oet4/gIFunK9Z/480MevvgP6ubd60MteZPCwbfbQlGWOWi0jiaYuHAJnGmN0AIvI2cJEx5hGgxsMCItIJKDDGFLpjRtdw3uWuL6vcLd8pjuKcX8Kt8rkOV7XG+R+zREQ+McZUu1NG1+ssBBaKyMfAm82Vr7kyuuYR+QvwqTFmnbvlaymNyYpzDzkBWI8bHonxiiKoRTyw/5Svs4Gh9TxnBvCyZYl+qrEZ3wWeFJFRwHIrg7k0Kp+IXAJMBCKBpyxN5tSofMaYewFE5FogvzlLoA6N/QzH4jyMEAR8YmWwUzT23+FtwDlAhIh0M875RazU2M8wCngYGCAiv3MVRkupLesTwFMich5nPgSFZby5CBrNGHO/3RnqYow5gbOs3JIx5l2cZeXWjDGv2J2hNsaYpcBSm2PUyRjzBM5vbG7JGHME5/kLt2GMKQausztHbdxuF6UZHQA6nvJ1gmuZO3H3jJqv6TRj07l7vlN5UtYfeHMRfAski0gXEQnEeZJwoc2ZTufuGTVf02nGpnP3fKfypKz/Y/fZ6uZ4AG8Bh/jfZZUzXMvPBXbgPIt/r2bUfJrRvTO6ez5PzVrfQwedU0opH+fNh4aUUko1gBaBUkr5OC0CpZTycVoESinl47QIlFLKx2kRKKWUj9MiUF5BRIpa+P2aZc4Kcc7hUCAi60Vkm4j8vQHPmSwivZvj/ZUCLQKlaiQidY7DZYwZ0Yxvt8IY0x8YAJwvIvXNQzAZ5wiqSjULLQLltUSkq4gsEpG14pw5radr+QUiskZEvhORxSIS61r+gIi8LiJfA6+7vn5JRJaKyG4Ruf2U1y5y/TrWtX6+6yf6ua5hmhGRc13L1orIEyLyUV15jTElOIcpjnc9f6aIfCsiG0RkgYiEiMgInPMVPOrai+ha259TqYbSIlDebA5wmzFmEPAb4BnX8q+AYcaYAcDbwG9PeU5v4BxjzJWur3viHFp7CHC/iATU8D4DgDtcz00CRopIMPA88HPX+0fXF1ZE2gDJ/G+I8XeNMYONMf2ArTiHMFiJc+yau4wx/Y0xu+r4cyrVIDoMtfJKIhIKjAD+4/oBHf43WU4C8I6ItMc5i9SeU5660PWT+UkfG2PKgDIRycU5+9rp03B+Y4zJdr3veiAR55Sdu40xJ1/7LWBWLXFHicgGnCXwL2NMjmt5iog8hHN+h1Dgs0b+OZVqEC0C5a0cwDHXsffTPQn80xiz0DURzAOnrCs+bduyU35fRc3/ZxqyTV1WGGPOF5EuwGoRmWeMWQ+8Akw2xmxwTaYztobn1vXnVKpB9NCQ8krGmOPAHhG5DJzTK4pIP9fqCP43Rvw1FkXYDiSdMpVhvZO8u/Ye/gLc7VoUBhxyHY6afsqmha519f05lWoQLQLlLUJEJPuUx69wfvOc4Trsshnn3LHg3AP4j4isBfKtCOM6vHQzsMj1PoVAQQOe+hww2lUgfwTWAF8D207Z5m3gLtfJ7q7U/udUqkF0GGqlLCIiocaYItdVRE8DO40xj9mdS6nT6R6BUtaZ6Tp5vBnn4ajn7Y2jVM10j0AppXyc7hEopZSP0yJQSikfp0WglFI+TotAKaV8nBaBUkr5OC0CpZTycf8Praus07e4VqUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63d5f3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.300086</td>\n",
       "      <td>2.000108</td>\n",
       "      <td>0.483025</td>\n",
       "      <td>0.478404</td>\n",
       "      <td>20:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.218320</td>\n",
       "      <td>1.177882</td>\n",
       "      <td>0.719365</td>\n",
       "      <td>0.721600</td>\n",
       "      <td>08:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.180899</td>\n",
       "      <td>0.332293</td>\n",
       "      <td>0.861431</td>\n",
       "      <td>0.859729</td>\n",
       "      <td>08:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.233202</td>\n",
       "      <td>0.891155</td>\n",
       "      <td>0.891315</td>\n",
       "      <td>08:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.133482</td>\n",
       "      <td>0.137459</td>\n",
       "      <td>0.932537</td>\n",
       "      <td>0.931869</td>\n",
       "      <td>08:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5,1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d552b5",
   "metadata": {},
   "source": [
    "### transfering to spatialsenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10276f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 1319)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_phrase_len = 2 #subjects/objects can be mutliple words. eg - microwave oven. max_phrase_len decides how many words are used to create embeddings\n",
    "word_embedding_dim = 300 #decides the dimension of the feature each word is converted into\n",
    "\n",
    "embedding = partial(phrase2vec, max_phrase_len = max_phrase_len, word_embedding_dim = word_embedding_dim)\n",
    "\n",
    "train_ds_spatialsenses = SpatialDataset(split = 'train',\n",
    "                          x_category_tfms = [embedding],\n",
    "                          y_category_tfms = [map_spatialsenses_to_stupd],\n",
    "                          x_img_tfms =     [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.RandomResizedCrop(224, scale=(0.75, 0.85)),\n",
    "                                            transforms.ColorJitter(0.1, 0.1, 0.1, 0.05)],\n",
    "            \n",
    "                          bbox_mask_tfms = [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.Pad(4, padding_mode=\"edge\"),\n",
    "                                            transforms.RandomResizedCrop(32, scale=(0.75, 0.85))]\n",
    "                         )\n",
    "\n",
    "valid_ds_spatialsenses = SpatialDataset(split = 'valid',\n",
    "                          x_category_tfms = [embedding],\n",
    "                          y_category_tfms = [map_spatialsenses_to_stupd],\n",
    "                          x_img_tfms =     [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.CenterCrop(224)],\n",
    "                          \n",
    "                          bbox_mask_tfms = [transforms.ToPILImage(\"RGB\"),\n",
    "                                            transforms.Pad(4, padding_mode=\"edge\"),\n",
    "                                            transforms.CenterCrop(32)]\n",
    "                         )\n",
    "\n",
    "len(train_ds_spatialsenses),len(valid_ds_spatialsenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60fd6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_spatialsenses = DataLoader(train_ds_spatialsenses, batch_size =64 , shuffle = True)\n",
    "valid_dl_spatialsenses = DataLoader(valid_ds_spatialsenses, batch_size = 128 , shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "812baa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_spatialsenses = DataLoaders(train_dl_spatialsenses, valid_dl_spatialsenses)\n",
    "dls_spatialsenses.n_inp = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b102b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls_spatialsenses, model = model, loss_func = CrossEntropyLossFlat(), metrics = [accuracy,BalancedAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5292ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f04c75bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.004365158267319202)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2dc64a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.033285</td>\n",
       "      <td>1.481162</td>\n",
       "      <td>0.456406</td>\n",
       "      <td>0.397416</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.529596</td>\n",
       "      <td>1.700956</td>\n",
       "      <td>0.378317</td>\n",
       "      <td>0.308105</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.413788</td>\n",
       "      <td>1.554729</td>\n",
       "      <td>0.407127</td>\n",
       "      <td>0.373806</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.324452</td>\n",
       "      <td>1.324203</td>\n",
       "      <td>0.532221</td>\n",
       "      <td>0.451049</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.251819</td>\n",
       "      <td>1.426720</td>\n",
       "      <td>0.454890</td>\n",
       "      <td>0.413758</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.180737</td>\n",
       "      <td>1.419866</td>\n",
       "      <td>0.491281</td>\n",
       "      <td>0.431986</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.089032</td>\n",
       "      <td>1.324581</td>\n",
       "      <td>0.532221</td>\n",
       "      <td>0.483949</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.983930</td>\n",
       "      <td>1.360993</td>\n",
       "      <td>0.532980</td>\n",
       "      <td>0.469005</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.904676</td>\n",
       "      <td>1.365500</td>\n",
       "      <td>0.539803</td>\n",
       "      <td>0.477737</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.851355</td>\n",
       "      <td>1.375829</td>\n",
       "      <td>0.535254</td>\n",
       "      <td>0.480205</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 5e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
